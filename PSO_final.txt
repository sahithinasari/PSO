import numpy as np

# Particle Swarm Optimization
def PSO(problem, MaxIter , PopSize, c1, c2, w , wdamp):

    # Empty Particle Template
    empty_particle = {
        'position': None, 
        'velocity': None, 
        'cost': None, 
        'best_position': None, 
        'best_cost': None, 
    }

    # Extract Problem Info
    CostFunction = problem['CostFunction']
    VarMin = problem['VarMin']
    VarMax = problem['VarMax']
    nVar = problem['nVar']

    # Initialize Global Best
    gbest = {'position': None, 'cost': np.inf}

    # Create Initial Population
    pop = []
    for i in range(0, PopSize):
        pop.append(empty_particle.copy())
        pop[i]['position'] = np.random.uniform(VarMin, VarMax, nVar)
        pop[i]['velocity'] = np.zeros(nVar)
        pop[i]['cost'] = CostFunction(pop[i]['position'])
        pop[i]['best_position'] = pop[i]['position'].copy()
        pop[i]['best_cost'] = pop[i]['cost']
        
        if pop[i]['best_cost'] < gbest['cost']:
            gbest['position'] = pop[i]['best_position'].copy()
            gbest['cost'] = pop[i]['best_cost']
    
    # PSO Loop
    for it in range(0, MaxIter):
        for i in range(0, PopSize):
            
            pop[i]['velocity'] = w*pop[i]['velocity'] \
                + c1*np.random.rand(nVar)*(pop[i]['best_position'] - pop[i]['position']) \
                + c2*np.random.rand(nVar)*(gbest['position'] - pop[i]['position'])

            pop[i]['position'] += pop[i]['velocity']
            pop[i]['position'] = np.maximum(pop[i]['position'], VarMin)
            pop[i]['position'] = np.minimum(pop[i]['position'], VarMax)

            pop[i]['cost'] = CostFunction(pop[i]['position'])
            
            if pop[i]['cost'] < pop[i]['best_cost']:
                pop[i]['best_position'] = pop[i]['position'].copy()
                pop[i]['best_cost'] = pop[i]['cost']

                if pop[i]['best_cost'] < gbest['cost']:
                    gbest['position'] = pop[i]['best_position'].copy()
                    gbest['cost'] = pop[i]['best_cost']

        w *= wdamp
        print('Iteration {}: Best Cost = {}'.format(it, gbest['cost']))

    return gbest, pop

# Start Time for tic and toc functions
startTime_for_tictoc = 0

# Start measuring time elapsed
def tic():
    import time
    global startTime_for_tictoc
    startTime_for_tictoc = time.time()

# End mesuring time elapsed
def toc():
    import time, math
    if 'startTime_for_tictoc' in globals():
        dt = math.floor(100*(time.time() - startTime_for_tictoc))/100.
        print('Elapsed time is {} second(s).'.format(dt))
    else:
        print('Start time not set. You should call tic before toc.')

from pyswarm import pso
import math

def Sphere(x):
    return sum(x**2)

# Define Optimization Problem
problem1 = {
        'CostFunction': Sphere, 
        'nVar': 10, 
        'VarMin': -5,   # Alternatively you can use a "numpy array" with nVar elements, instead of scalar
        'VarMax': 5,    # Alternatively you can use a "numpy array" with nVar elements, instead of scalar
    }
def rastrigin_fn(x):
	total = 0

	for i in range(len(x)):
		total += ( x[i]**2 - 10 * (math.cos(2 * math.pi * x[i])) + 10 )
	return total

# Define Optimization Problem
problem2= {
        'CostFunction': rastrigin_fn, 
        'nVar': 10, 
        'VarMin': -5,   # Alternatively you can use a "numpy array" with nVar elements, instead of scalar
        'VarMax': 5,    # Alternatively you can use a "numpy array" with nVar elements, instead of scalar
    }
def griewank_fn(x):
	total = 0
	total1 = 0
	total2 = 1

	for i in range(len(x)):
		total1 += ( (x[i]**2 / 4000) )

	for i in range(len(x)):
		total2 *= ( math.cos(x[i] / math.sqrt(i + 1)) )

	total = 1 + total1 - total2
	return total
# Define Optimization Problem
problem3= {
        'CostFunction': griewank_fn, 
        'nVar': 10, 
        'VarMin': -5,   # Alternatively you can use a "numpy array" with nVar elements, instead of scalar
        'VarMax': 5,    # Alternatively you can use a "numpy array" with nVar elements, instead of scalar
    }
def rosenbrock_fn(x):
	total = 0

	for i in range(len(x) - 1):
		total += ( 100 * ((x[i + 1] - x[i]**2)**2) + (x[i] - 1)**2 )
	return total
# Define Optimization Problem
problem4= {
        'CostFunction': rosenbrock_fn, 
        'nVar': 10, 
        'VarMin': -5,   # Alternatively you can use a "numpy array" with nVar elements, instead of scalar
        'VarMax': 5,    # Alternatively you can use a "numpy array" with nVar elements, instead of scalar
    }
list=[problem1,problem2,problem3,problem4]
# Running PSO
tic()
print('Running PSO ...')

for i in range(0,4):
  gbest, pop = PSO(list[i], MaxIter = 10, PopSize = 15, c1 = 1.5, c2 = 2.7, w = 1, wdamp = 0.995)
  print(list[i],"completed")
print()
toc()
print()


# Final Result
print('Global Best:')
print(gbest)
print()
